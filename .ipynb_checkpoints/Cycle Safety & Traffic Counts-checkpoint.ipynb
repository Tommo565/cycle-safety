{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cycle Safety Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyproj\n",
    "import warnings\n",
    "import zipfile\n",
    "from scipy.spatial import cKDTree\n",
    "from pyproj import Proj, transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))       # Changing the cell widths\n",
    "\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning, message='.*use @default decorator instead.*')\n",
    "                                                                            # Getting rid of annoying warnings\n",
    "\n",
    "pd.options.display.max_rows = 30                                            # Setting the max number of rows\n",
    "pd.options.display.max_columns = 40                                         # Setting the max number of columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses the following data sources:\n",
    "\n",
    "AADF Data: https://data.gov.uk/dataset/gb-road-traffic-counts/datapackage.zip<br>\n",
    "AADF Metadata: http://data.dft.gov.uk/gb-traffic-matrix/aadf-majorroads-metadata.pdf<br>\n",
    "Casualty Data: https://data.gov.uk/dataset/road-accidents-safety-data/datapackage.zip<br>\n",
    "Casualty Variable Decodes: http://data.dft.gov.uk/road-accidents-safety-data/Road-Accident-Safety-Data-Guide.xls<br>\n",
    "\n",
    "You will need to download the two data files above and save the zip files into the path directory specified below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "year = 2015\n",
    "\n",
    "path = 'data/'\n",
    "out = 'out/'\n",
    "counts_file = 'gb-road-traffic-counts.zip'\n",
    "casualties_file = 'road-accidents-safety-data.zip'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traffic Count Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files = set(['AADF-data-major-roads','AADF-data-minor-roads'])               # List of relevent files to import\n",
    "\n",
    "tc_dict = {}                                                                 # Blank Dictionary to store the casualties dataframes\n",
    "\n",
    "for file in files:\n",
    "    # Zip Files\n",
    "    tc_files = zipfile.ZipFile(path + counts_file, mode='r')                 # Level 1 location\n",
    "    tc_ext = tc_files.extract('data/{}.zip'.format(file))                    # Level 1 extraction\n",
    "    ind_file = zipfile.ZipFile(tc_ext, mode='r')                             # Level 2 location\n",
    "    ind_ext = ind_file.extract('{}.csv'.format(file))                        # Level 2 extraction\n",
    "    \n",
    "    # Dataframe\n",
    "    df = pd.read_csv(ind_ext,low_memory=False)                               # Creating the dataframe\n",
    "    df = df[(df['AADFYear'] == year)]                                        # Limiting to the specified year\n",
    "    tc_dict['df_' + file.split('-')[2].lower()] = df                         # Appending the dataframe into the df_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_tc_raw = pd.concat([tc_dict['df_major'],tc_dict['df_minor']])\n",
    "df_tc_raw = df_tc_raw.reset_index().drop(['index'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting E / N to Lat / Lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Some Basic Cleaning\n",
    "\n",
    "df_tc = df_tc_raw.drop(['ONS GOR Name', 'ONS LA Name','AADFYear','A-Junction','B-Junction','LenNet','LenNet_miles','RCat'],axis=1)    # Keeps only the latest year & drops unwanted variables\n",
    "\n",
    "# Creating a master Goods Vehicle Variable\n",
    "\n",
    "df_tc['FdAll_GV'] = sum([df_tc['FdHGV'], df_tc['FdHGVA3'],df_tc['FdHGVA5'], df_tc['FdHGVA6'], df_tc['FdHGVR2'], df_tc['FdHGVR3'], df_tc['FdHGVR4'], df_tc['FdLGV']])\n",
    "df_tc = df_tc.drop(['FdHGV', 'FdHGVA3','FdHGVA5', 'FdHGVA6', 'FdHGVR2', 'FdHGVR3', 'FdHGVR4', 'FdLGV'],axis=1)\n",
    "\n",
    "# Setting the Projections\n",
    "\n",
    "bng = Proj(\"+proj=tmerc +lat_0=49 +lon_0=-2 +k=0.9996012717 +x_0=400000 +y_0=-100000 +ellps=airy +datum=OSGB36 +units=m +no_defs towgs84='446.448,-125.157,542.060,0.1502,0.2470,0.8421,-20.4894'\")\n",
    "wgs84 = Proj('+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs')\n",
    "\n",
    "# Converting columns to lists to pass to pyproj:\n",
    "\n",
    "Easting = df_tc['S Ref E'].tolist()                                     # Convert Easting to List\n",
    "Northing = df_tc['S Ref N'].tolist()                                    # Convert Northing to List\n",
    "Lon_S,Lat_S = pyproj.transform(bng,wgs84,Easting,Northing)              # Performing the conversion:\n",
    "LL = pd.DataFrame(Lat_S,Lon_S)                                          # Creating a DataFram\n",
    "LL.reset_index(inplace='True')                                          # Reset the Index\n",
    "LL.rename(columns={'index':'Lon_S',0:'Lat_S'}, inplace='True')          # Rename the columns\n",
    "rep = [-7.557159842082696,49.76680723189604]                            # Lat / Lon co-ords for where the data is missing\n",
    "LL = LL.replace(rep,np.nan)                                             # Replacing missing lat / lon values with nan\n",
    "\n",
    "df_tc = df_tc.merge(LL,left_index='True',right_index='True',how='outer')\\\n",
    "             .drop(['S Ref E','S Ref N'],axis=1)                        # Merging on to the master dataset & Dropping the Eastings / Northings column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Dataframes to merge with Casualties Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_tc['1st_Road_Class'] = df_tc['Road'].str[0:1]                                                                 # Creating the 1st Road Class variable\n",
    "road_list = df_tc['Road'].unique().tolist()                                                                      # List of road names\n",
    "road_list.remove('C')                                                                                            # Removing C Roads\n",
    "road_list.remove('U')                                                                                            # Removing U Roads\n",
    "type_list = ['A','B','M','C','U']                                                                                # List of road types\n",
    " \n",
    "name_counts = {'{}'.format(road_name): df_tc[(df_tc['Road'] == road_name)] for road_name in road_list}           # Dictionary containing traffic count dataframes for each road name\n",
    "type_counts = {'{}'.format(road_type): df_tc[(df_tc['1st_Road_Class'] == road_type)] for road_type in type_list} # Dictionary containing traffic count dataframes for each road type\n",
    "\n",
    "for road_name in road_list:\n",
    "    name_counts[road_name] = name_counts[road_name].reset_index().drop(['index'],axis=1)\n",
    "\n",
    "for road_type in type_list:\n",
    "    type_counts[road_type] = type_counts[road_type].reset_index().drop(['index'],axis=1)\n",
    "\n",
    "# Creating Sets out of the road and type lists to improve performance\n",
    "    \n",
    "road_set = set(road_list)\n",
    "type_set = set(type_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Casualties Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files = set(['DfTRoadSafety_Vehicles_' + str(year),\n",
    "             'DfTRoadSafety_Accidents_' + str(year),\n",
    "             'DfTRoadSafety_Casualties_' + str(year)])                        # List of relevent files to import\n",
    "\n",
    "cas_dict = {}                                                                 # Blank Dictionary to store the casualties dataframes\n",
    "\n",
    "for file in files:\n",
    "    # Zip Files\n",
    "    cas_files = zipfile.ZipFile(path + casualties_file, mode='r')             # Level 1 location\n",
    "    cas_ext = cas_files.extract('data/{}.zip'.format(file))                   # Level 1 extraction\n",
    "    ind_file = zipfile.ZipFile(cas_ext, mode='r')                             # Level 2 location\n",
    "    ind_ext = ind_file.extract('{}.csv'.format(file))                         # Level 2 extraction\n",
    "\n",
    "    # Dataframe\n",
    "    df = pd.read_csv(ind_ext,low_memory=False)                                # Creating the dataframe\n",
    "    df.rename(columns={'﻿Accident_Index':'Accident_Index'},inplace=True)      # Renaming the Accident Index variable due to a wierd character\n",
    "    cas_dict['df_' + file.split('_')[1].lower()] = df                         # Appending the dataframe into the df_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe reference variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_v = cas_dict['df_vehicles']  # Vehicles data not required (yet)\n",
    "\n",
    "df_c = cas_dict['df_casualties']\n",
    "df_c_cols = ['Accident_Index','Casualty_Class','Sex_of_Casualty','Age_of_Casualty','Casualty_Severity','Casualty_Type']\n",
    "\n",
    "df_a = cas_dict['df_accidents']\n",
    "df_a_cols = ['Accident_Index','Police_Force','Longitude','Latitude','Junction_Detail','Junction_Control','Number_of_Vehicles','Number_of_Casualties','Date','Day_of_Week','Time','1st_Road_Class','1st_Road_Number',\n",
    "             'Road_Type','Speed_limit','Light_Conditions','Weather_Conditions','Road_Surface_Conditions','Urban_or_Rural_Area']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging the Accidents & Casualties Dataframes together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_a = df_a[df_a_cols].drop_duplicates()          \n",
    "df_c = df_c[df_c_cols].drop_duplicates()\n",
    "cas_dict['df_cas'] = df_c.merge(df_a,left_on='Accident_Index',right_on='Accident_Index',how='inner').drop_duplicates()\n",
    "df_cas = cas_dict['df_cas']\n",
    "\n",
    "df_cas = df_cas.reset_index().drop(['index'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining functions to decode variable values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def casualty_class(row):\n",
    "    if row[\"Casualty_Class\"] == 1:\n",
    "        return \"Driver or rider\"\n",
    "    elif row[\"Casualty_Class\"] == 2:\n",
    "        return \"Passenger\"\n",
    "    elif row[\"Casualty_Class\"] == 3:\n",
    "        return \"Pedestrian\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "    \n",
    "def sex_of_casualty(row):\n",
    "    if row[\"Sex_of_Casualty\"] == 1:\n",
    "        return \"Male\"\n",
    "    elif row[\"Sex_of_Casualty\"] == 2:\n",
    "        return \"Female\"\n",
    "    else:\n",
    "        return \"Unknown\"  \n",
    "    \n",
    "def casualty_severity(row):\n",
    "    if row[\"Casualty_Severity\"] == 1:\n",
    "        return \"Fatal\"\n",
    "    elif row[\"Casualty_Severity\"] == 2:\n",
    "        return \"Serious\"\n",
    "    elif row[\"Casualty_Severity\"] == 3:\n",
    "        return \"Slight\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "    \n",
    "def casualty_type(row):\n",
    "    if row[\"Casualty_Type\"] == 0:\n",
    "        return \"Pedestrian\"   \n",
    "    elif row[\"Casualty_Type\"] == 1:\n",
    "        return \"Cyclist\"  \n",
    "    elif row[\"Casualty_Type\"] == 2:\n",
    "        return \"Motorcycle 50cc and under rider or passenger\" \n",
    "    elif row[\"Casualty_Type\"] == 3:\n",
    "        return \"Motorcycle 125cc and under rider or passenger\"     \n",
    "    elif row[\"Casualty_Type\"] == 4:\n",
    "        return \"Motorcycle over 125cc and up to 500cc rider or  passenger\" \n",
    "    elif row[\"Casualty_Type\"] == 5:\n",
    "        return \"Motorcycle over 500cc rider or passenger\"     \n",
    "    elif row[\"Casualty_Type\"] == 8:\n",
    "        return \"Taxi/Private hire car occupant\"  \n",
    "    elif row[\"Casualty_Type\"] == 9:\n",
    "        return \"Car occupant\"  \n",
    "    elif row[\"Casualty_Type\"] == 10:\n",
    "        return \"Minibus (8 - 16 passenger seats) occupant\"  \n",
    "    elif row[\"Casualty_Type\"] == 11:\n",
    "        return \"Bus or coach occupant (17 or more pass seats)\"      \n",
    "    elif row[\"Casualty_Type\"] == 16:\n",
    "        return \"Horse rider\"   \n",
    "    elif row[\"Casualty_Type\"] == 17:\n",
    "        return \"Agricultural vehicle occupant\"   \n",
    "    elif row[\"Casualty_Type\"] == 18:\n",
    "        return \"Tram occupant\"   \n",
    "    elif row[\"Casualty_Type\"] == 19:\n",
    "        return \"Van / Goods vehicle (3.5 tonnes mgw or under) occupant\"   \n",
    "    elif row[\"Casualty_Type\"] == 20:\n",
    "        return \"Goods vehicle (over 3.5t. and under 7.5t.) occupant\"   \n",
    "    elif row[\"Casualty_Type\"] == 21:\n",
    "        return \"Goods vehicle (7.5 tonnes mgw and over) occupant\"  \n",
    "    elif row[\"Casualty_Type\"] == 22:\n",
    "        return \"Mobility scooter rider\"  \n",
    "    elif row[\"Casualty_Type\"] == 23:\n",
    "        return \"Electric motorcycle rider or passenger\"  \n",
    "    elif row[\"Casualty_Type\"] == 90:\n",
    "        return \"Other vehicle occupant\"  \n",
    "    elif row[\"Casualty_Type\"] == 97:\n",
    "        return \"Motorcycle - unknown cc rider or passenger\"  \n",
    "    elif row[\"Casualty_Type\"] == 98:\n",
    "        return \"Goods vehicle (unknown weight) occupant\"     \n",
    "    \n",
    "def police_force(row):\n",
    "    if row[\"Police_Force\"] == 1:\n",
    "        return \"Metropolitan Police\"\n",
    "    elif row[\"Police_Force\"] == 3:\n",
    "        return \"Cumbria\"\n",
    "    elif row[\"Police_Force\"] == 4:\n",
    "        return \"Lancashire\"\n",
    "    elif row[\"Police_Force\"] == 5:\n",
    "        return \"Merseyside\"\n",
    "    elif row[\"Police_Force\"] == 6:\n",
    "        return \"Greater Manchester\"\n",
    "    elif row[\"Police_Force\"] == 7:\n",
    "        return \"Cheshire\"\n",
    "    elif row[\"Police_Force\"] == 10:\n",
    "        return \"Northumbria\"\n",
    "    elif row[\"Police_Force\"] == 11:\n",
    "        return \"Durham\"\n",
    "    elif row[\"Police_Force\"] == 12:\n",
    "        return \"North Yorkshire\"\n",
    "    elif row[\"Police_Force\"] == 13:\n",
    "        return \"West Yorkshire\"\n",
    "    elif row[\"Police_Force\"] == 14:\n",
    "        return \"South Yorkshire\"\n",
    "    elif row[\"Police_Force\"] == 16:\n",
    "        return \"Humberside\"\n",
    "    elif row[\"Police_Force\"] == 17:\n",
    "        return \"Cleveland\"\n",
    "    elif row[\"Police_Force\"] == 20:\n",
    "        return \"West Midlands\"\n",
    "    elif row[\"Police_Force\"] == 21:\n",
    "        return \"Staffordshire\"\n",
    "    elif row[\"Police_Force\"] == 22:\n",
    "        return \"West Mercia\"\n",
    "    elif row[\"Police_Force\"] == 23:\n",
    "        return \"Warwickshire\"\n",
    "    elif row[\"Police_Force\"] == 30:\n",
    "        return \"Derbyshire\"\n",
    "    elif row[\"Police_Force\"] == 31:\n",
    "        return \"Nottinghamshire\"\n",
    "    elif row[\"Police_Force\"] == 32:\n",
    "        return \"Lincolnshire\"\n",
    "    elif row[\"Police_Force\"] == 33:\n",
    "        return \"Leicestershire\"\n",
    "    elif row[\"Police_Force\"] == 34:\n",
    "        return \"Northamptonshire\"\n",
    "    elif row[\"Police_Force\"] == 35:\n",
    "        return \"Cambridgeshire\"\n",
    "    elif row[\"Police_Force\"] == 36:\n",
    "        return \"Norfolk\"\n",
    "    elif row[\"Police_Force\"] == 37:\n",
    "        return \"Suffolk\"\n",
    "    elif row[\"Police_Force\"] == 40:\n",
    "        return \"Bedfordshire\"\n",
    "    elif row[\"Police_Force\"] == 41:\n",
    "        return \"Hertfordshire\"\n",
    "    elif row[\"Police_Force\"] == 42:\n",
    "        return \"Essex\"\n",
    "    elif row[\"Police_Force\"] == 43:\n",
    "        return \"Thames Valley\"\n",
    "    elif row[\"Police_Force\"] == 44:\n",
    "        return \"Hampshire\"\n",
    "    elif row[\"Police_Force\"] == 45:\n",
    "        return \"Surrey\"\n",
    "    elif row[\"Police_Force\"] == 46:\n",
    "        return \"Kent\"\n",
    "    elif row[\"Police_Force\"] == 47:\n",
    "        return \"Sussex\"\n",
    "    elif row[\"Police_Force\"] == 48:\n",
    "        return \"City of London\"\n",
    "    elif row[\"Police_Force\"] == 50:\n",
    "        return \"Devon and Cornwall\"\n",
    "    elif row[\"Police_Force\"] == 52:\n",
    "        return \"Avon and Somerset\"\n",
    "    elif row[\"Police_Force\"] == 53:\n",
    "        return \"Gloucestershire\"\n",
    "    elif row[\"Police_Force\"] == 54:\n",
    "        return \"Wiltshire\"\n",
    "    elif row[\"Police_Force\"] == 55:\n",
    "        return \"Dorset\"\n",
    "    elif row[\"Police_Force\"] == 60:\n",
    "        return \"North Wales\"\n",
    "    elif row[\"Police_Force\"] == 61:\n",
    "        return \"Gwent\"\n",
    "    elif row[\"Police_Force\"] == 62:\n",
    "        return \"South Wales\"\n",
    "    elif row[\"Police_Force\"] == 63:\n",
    "        return \"Dyfed-Powys\"\n",
    "    elif row[\"Police_Force\"] == 91:\n",
    "        return \"Northern\"\n",
    "    elif row[\"Police_Force\"] == 92:\n",
    "        return \"Grampian\"\n",
    "    elif row[\"Police_Force\"] == 93:\n",
    "        return \"Tayside\"\n",
    "    elif row[\"Police_Force\"] == 94:\n",
    "        return \"Fife\"\n",
    "    elif row[\"Police_Force\"] == 95:\n",
    "        return \"Lothian and Borders\"\n",
    "    elif row[\"Police_Force\"] == 96:\n",
    "        return \"Central\"\n",
    "    elif row[\"Police_Force\"] == 97:\n",
    "        return \"Strathclyde\"\n",
    "    elif row[\"Police_Force\"] == 98:\n",
    "        return \"Dumfries and Galloway\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "def junction_detail(row):\n",
    "    if row[\"Junction_Detail\"] == 0:\n",
    "        return \"Not at junction or within 20 metres\"\n",
    "    elif row[\"Junction_Detail\"] == 1:\n",
    "        return \"Roundabout\"\n",
    "    elif row[\"Junction_Detail\"] == 2:\n",
    "        return \"Mini-roundabout\"   \n",
    "    elif row[\"Junction_Detail\"] == 3:\n",
    "        return \"T or staggered junction\"   \n",
    "    elif row[\"Junction_Detail\"] == 5:\n",
    "        return \"Slip road\"   \n",
    "    elif row[\"Junction_Detail\"] == 6:\n",
    "        return \"Crossroads\"   \n",
    "    elif row[\"Junction_Detail\"] == 7:\n",
    "        return \"More than 4 arms (not roundabout)\"   \n",
    "    elif row[\"Junction_Detail\"] == 8:\n",
    "        return \"Private drive or entrance\"   \n",
    "    elif row[\"Junction_Detail\"] == 9:\n",
    "        return \"Other junction\"   \n",
    "    else:\n",
    "        return \"Unknown\"   \n",
    "\n",
    "def junction_control(row):\n",
    "    if row[\"Junction_Control\"] == 0:\n",
    "        return \"Not at junction or within 20 metres\"\n",
    "    elif row[\"Junction_Control\"] == 1:\n",
    "        return \"Authorised person\"    \n",
    "    elif row[\"Junction_Control\"] == 2:\n",
    "        return \"Auto traffic signal\"\n",
    "    elif row[\"Junction_Control\"] == 3:\n",
    "        return \"Stop sign\"\n",
    "    elif row[\"Junction_Control\"] == 4:\n",
    "        return \"Give way or uncontrolled\"   \n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "    \n",
    "def is_junction(row):\n",
    "    if row['Junction_Detail'] in ['T or staggered junction','Crossroads','Roundabout','Mini-roundabout','Slip road','Junction - more than 4 arms (not roundabout)','Other junction']:\n",
    "        return \"Junction\"\n",
    "    else:\n",
    "        return \"Not a Junction\"\n",
    "    \n",
    "def day_of_week(row):\n",
    "    if row[\"Day_of_Week\"] == 1:\n",
    "        return \"Sunday\"\n",
    "    elif row[\"Day_of_Week\"] == 2:\n",
    "        return \"Monday\"\n",
    "    elif row[\"Day_of_Week\"] == 3:\n",
    "        return \"Tuesday\"    \n",
    "    elif row[\"Day_of_Week\"] == 4:\n",
    "        return \"Wednesday\"    \n",
    "    elif row[\"Day_of_Week\"] == 5:\n",
    "        return \"Thursday\"  \n",
    "    elif row[\"Day_of_Week\"] == 6:\n",
    "        return \"Friday\"    \n",
    "    elif row[\"Day_of_Week\"] == 7:\n",
    "        return \"Saturday\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "    \n",
    "def day_type(row):\n",
    "    if row['Day_of_Week'] in ['Saturday','Sunday']:\n",
    "        return 'Weekend'\n",
    "    elif row['Day_of_Week'] in ['Monday','Tuesday','Wednesday','Thursday','Friday']:\n",
    "        return 'Weekday'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "      \n",
    "def first_road_class(row):\n",
    "    if row[\"1st_Road_Class\"] == 1:\n",
    "        return \"Motorway\"\n",
    "    if row[\"1st_Road_Class\"] == 2:\n",
    "        return \"A\"    \n",
    "    if row[\"1st_Road_Class\"] == 3:\n",
    "        return \"A\"   \n",
    "    if row[\"1st_Road_Class\"] == 4:\n",
    "        return \"B\"      \n",
    "    if row[\"1st_Road_Class\"] == 5:\n",
    "        return \"C\"      \n",
    "    else:\n",
    "        return \"U\"\n",
    "\n",
    "def road_name(row):\n",
    "    if row[\"1st_Road_Class\"] in ['A','B','M']:\n",
    "        return row['1st_Road_Class'] + str(row['1st_Road_Number'])\n",
    "    else:\n",
    "        return row['1st_Road_Class']\n",
    "    \n",
    "def road_type(row):\n",
    "    if row[\"Road_Type\"] == 1:\n",
    "        return \"Roundabout\"\n",
    "    elif row[\"Road_Type\"] == 2:\n",
    "        return \"One way street\"\n",
    "    elif row[\"Road_Type\"] == 3:\n",
    "        return \"Dual carriageway\"\n",
    "    elif row[\"Road_Type\"] == 6:\n",
    "        return \"Single carriageway\"    \n",
    "    elif row[\"Road_Type\"] == 7:\n",
    "        return \"Slip road\"    \n",
    "    elif row[\"Road_Type\"] == 9:\n",
    "        return \"Unknown\"\n",
    "    elif row[\"Road_Type\"] == 12:\n",
    "        return \"One way street/Slip road\"\n",
    "    else: \n",
    "        return \"Unknown\"\n",
    "    \n",
    "def light_conditions(row):\n",
    "    if row[\"Light_Conditions\"] == 1:\n",
    "        return \"Daylight\"\n",
    "    elif row[\"Light_Conditions\"] == 4:\n",
    "        return \"Darkness - lights lit\" \n",
    "    elif row[\"Light_Conditions\"] == 5:\n",
    "        return \"Darkness - lights unlit\"     \n",
    "    elif row[\"Light_Conditions\"] == 6:\n",
    "        return \"no lighting\"       \n",
    "    elif row[\"Light_Conditions\"] == 7:\n",
    "        return \"lighting unknown\"     \n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "def weather_conditions(row):\n",
    "    if row[\"Weather_Conditions\"] == 1:\n",
    "        return \"Fine no high winds\"\n",
    "    elif row[\"Weather_Conditions\"] == 2:\n",
    "        return \"Raining no high winds\"\n",
    "    elif row[\"Weather_Conditions\"] == 3:\n",
    "        return \"Snowing no high winds\"    \n",
    "    elif row[\"Weather_Conditions\"] == 4:\n",
    "        return \"Fine + high winds\"    \n",
    "    elif row[\"Weather_Conditions\"] == 5:\n",
    "        return \"Raining + high winds\"\n",
    "    elif row[\"Weather_Conditions\"] == 6:\n",
    "        return \"Snowing + high winds\"    \n",
    "    elif row[\"Weather_Conditions\"] == 7:\n",
    "        return \"Fog or mist\"    \n",
    "    elif row[\"Weather_Conditions\"] == 8:\n",
    "        return \"Other\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "    \n",
    "def road_surface_conditions(row):\n",
    "    if row[\"Road_Surface_Conditions\"] == 1: \n",
    "        return \"Dry\"\n",
    "    elif row[\"Road_Surface_Conditions\"] == 2: \n",
    "        return \"Wet or damp\"\n",
    "    elif row[\"Road_Surface_Conditions\"] == 3: \n",
    "        return \"Snow\"\n",
    "    elif row[\"Road_Surface_Conditions\"] == 4: \n",
    "        return \"Frost or ice\" \n",
    "    elif row[\"Road_Surface_Conditions\"] == 5: \n",
    "        return \"Flood over 3cm. deep\"\n",
    "    elif row[\"Road_Surface_Conditions\"] == 6: \n",
    "        return \"Oil or diesel\"\n",
    "    elif row[\"Road_Surface_Conditions\"] == 7: \n",
    "        return \"Mud\"\n",
    "    else:\n",
    "        return \"Unknown\"     \n",
    "    \n",
    "def urban_or_rural_area(row):\n",
    "    if row[\"Urban_or_Rural_Area\"] == 1:\n",
    "        return \"Urban\"\n",
    "    elif row[\"Urban_or_Rural_Area\"] == 2:\n",
    "        return \"Rural\"\n",
    "    else:\n",
    "        return \"Unknown\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling functions to decode variable values & creating more meaningful columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_cas['Police_Force'] = df_cas.apply(police_force,axis=1)\n",
    "df_cas['Casualty_Class'] = df_cas.apply(casualty_class,axis=1)\n",
    "df_cas['Sex_of_Casualty'] = df_cas.apply(sex_of_casualty,axis=1)\n",
    "df_cas['Casualty_Severity'] = df_cas.apply(casualty_severity,axis=1)\n",
    "df_cas['Casualty_Type'] = df_cas.apply(casualty_type,axis=1)\n",
    "df_cas['geo'] = df_cas['Longitude'].apply(str) + ',' + df_cas['Latitude'].apply(str)\n",
    "df_cas['Junction_Detail'] = df_cas.apply(junction_detail,axis=1)\n",
    "df_cas['Junction_Control'] = df_cas.apply(junction_control,axis=1)\n",
    "df_cas['Junction'] = df_cas.apply(is_junction,axis=1)\n",
    "df_cas['Day_of_Week'] = df_cas.apply(day_of_week,axis=1)\n",
    "df_cas['Day_Type'] = df_cas.apply(day_type,axis=1)\n",
    "df_cas['1st_Road_Class'] = df_cas.apply(first_road_class,axis=1)\n",
    "df_cas['Road_Name'] = df_cas.apply(road_name,axis=1)\n",
    "df_cas['Road_Type'] = df_cas.apply(road_type,axis=1)\n",
    "df_cas['Light_Conditions'] = df_cas.apply(light_conditions,axis=1)\n",
    "df_cas['Weather_Conditions'] = df_cas.apply(weather_conditions,axis=1)\n",
    "df_cas['Road_Surface_Conditions'] = df_cas.apply(road_surface_conditions,axis=1)\n",
    "df_cas['Urban_or_Rural_Area'] = df_cas.apply(urban_or_rural_area,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Traffic Count Values to the Casualty Locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the K nearest neighbours (Knn) algorithm to merge the casualty and traffic counts data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Knn_func(row):\n",
    "    \n",
    "    '''K Nearest Neighbours Machine Learning algortihm to match the Casualty Point with the two most appropriate Traffic Count Points. \n",
    "    The Algorithm firstly tries to match the specific road name (e.g. A315) and if no match can be made, it matches on Road Type (e.g. ('A' Road)). \n",
    "    It returns the following variables:\n",
    "    * Accident Index\n",
    "    * Road Name\n",
    "    * Road Type\n",
    "    * Distance to relevent Count Point 1\n",
    "    * Distance to relevent Count Point 2\n",
    "    * Index of Relevent Count Point 1\n",
    "    * Index of Relevent Count Point 2'''\n",
    "    \n",
    "    # Creating base variables to aid readibility\n",
    "    \n",
    "    road = row['Road_Name']\n",
    "    accid = row['Accident_Index']\n",
    "    rtype = row['1st_Road_Class']\n",
    "    cas_pt = row[['Longitude','Latitude']].values\n",
    "    \n",
    "    # If the Roadname is known then match with traffic counts based upon that:\n",
    "    \n",
    "    if road in road_set: \n",
    "        tree = cKDTree(name_counts[road][['Lon_S','Lat_S']])                 # Creating the tree from the Traffic Count data\n",
    "        dists, indexes = tree.query(cas_pt, k=2)                             # Querying the tree with the Casualty Point\n",
    "        assign = 'Road Name'\n",
    "        return accid, assign, road, rtype, dists[0], dists[1], int(indexes[0]),int(indexes[1]) # Returning the data\n",
    "    \n",
    "    # Else match based upon the Road Class:\n",
    "    \n",
    "    elif rtype in type_set:\n",
    "        tree = cKDTree(type_counts[rtype][['Lon_S','Lat_S']])                 # Creating the tree from the Traffic Count data\n",
    "        dists, indexes = tree.query(cas_pt, k=2)                              # Querying the tree with the Casualty Point\n",
    "        assign = 'Road Type'\n",
    "        return accid, assign, road, rtype, dists[0], dists[1], int(indexes[0]),int(indexes[1])  # Returning the data\n",
    "        \n",
    "    # Else return blank values:\n",
    "    \n",
    "    else:\n",
    "        assign = 'None'\n",
    "        return accid, assign, 'None', 'None', np.nan, np.nan, np.nan, np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying the Knn algorithm and cleaning / formatting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_knn_func = df_cas[['Road_Name','Accident_Index','1st_Road_Class','Longitude','Latitude']].drop_duplicates()\n",
    "knn = df_knn_func.apply(Knn_func,axis=1).to_dict() \n",
    "\n",
    "df_knn = pd.DataFrame.from_dict(knn, orient='index') # Converting the output dictionary to a dataframe\n",
    "df_knn.replace([np.inf, -np.inf], np.nan)            # Replacing infinite values with nan's\n",
    "knn_cols = ['Accident_Index','Assign_Type','Road_Name','1st_Road_Class','Distance_1','Distance_2','CP_Index_1','CP_Index_2'] \n",
    "df_knn.columns = knn_cols                            # Column naming\n",
    "df_knn = df_knn.drop_duplicates()                    # Removing duplicates caused by multiple casualties per Accident Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Dicts of Road Names and Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name1 = {\n",
    "    'CP':'CP_1',\n",
    "    'Lon_Lat':'Lon_Lat_1',\n",
    "    'Road':'Road_1',\n",
    "    'Lon_S':'Lon_S_1',\n",
    "    'Lat_S': 'Lat_S_1',\n",
    "    'FdAll_MV':'FdAll_MV_1', \n",
    "    'FdPC':'FdPC_1',\n",
    "    'Fd2WMV':'Fd2WMV_1',\n",
    "    'FdCar':'FdCar_1', \n",
    "    'FdBUS':'FdBUS_1', \n",
    "    'FdAll_GV':'FdAll_GV_1',\n",
    "    '1st_Road_Class_x':'1st_Road_Class'\n",
    "}\n",
    "\n",
    "name2 = {\n",
    "    'CP':'CP_2',\n",
    "    'Lon_Lat':'Lon_Lat_2',\n",
    "    'Road':'Road_2',\n",
    "    'Lon_S':'Lon_S_2',\n",
    "    'Lat_S': 'Lat_S_2',\n",
    "    'FdAll_MV':'FdAll_MV_2', \n",
    "    'FdPC':'FdPC_2',\n",
    "    'Fd2WMV':'Fd2WMV_2',\n",
    "    'FdCar':'FdCar_2', \n",
    "    'FdBUS':'FdBUS_2', \n",
    "    'FdAll_GV':'FdAll_GV_2',\n",
    "    '1st_Road_Class_x':'1st_Road_Class'\n",
    "}\n",
    "\n",
    "# Creates dicts for Road Name and Type containing individual dataframes of Knn data: \n",
    "\n",
    "names_knn = {}\n",
    "types_knn = {}\n",
    "\n",
    "for road_name in road_list:\n",
    "    names_knn[road_name] = df_knn[(df_knn['Assign_Type'] == 'Road Name') & (df_knn['Road_Name'] == road_name)]\n",
    "    \n",
    "for road_type in type_list:\n",
    "    types_knn[road_type] = df_knn[(df_knn['Assign_Type'] == 'Road Type') & (df_knn['1st_Road_Class'] == road_type)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging the Casualty data with the traffic count data using the appropriate index variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_roadname_1 = {'{}'.format(road_name): pd.merge(names_knn[road_name],name_counts[road_name],left_on='CP_Index_1',right_index=True,how='left') for road_name in road_list}\n",
    "\n",
    "for road_name in road_list:\n",
    "    df_roadname_1[road_name].rename(columns=name1,inplace='True')\n",
    "\n",
    "df_roadname_2 = {'{}'.format(road_name): pd.merge(df_roadname_1[road_name],name_counts[road_name],left_on='CP_Index_2',right_index=True,how='left') for road_name in road_list}\n",
    "\n",
    "for road_name in road_list:\n",
    "    df_roadname_2[road_name].rename(columns=name2, inplace='True')\n",
    "    df_roadname_2[road_name].drop(['1st_Road_Class_y'],axis=1,inplace='True')\n",
    "\n",
    "# Road type data:\n",
    "\n",
    "df_roadtype_1 = {'{}'.format(road_type): pd.merge(types_knn[road_type],type_counts[road_type],left_on='CP_Index_1',right_index=True,how='left') for road_type in type_list}\n",
    "\n",
    "for road_type in type_list:\n",
    "    df_roadtype_1[road_type].rename(columns=name1,inplace='True')\n",
    "    \n",
    "df_roadtype_2 = {'{}'.format(road_type): pd.merge(df_roadtype_1[road_type],type_counts[road_type],left_on='CP_Index_2',right_index=True,how='left') for road_type in type_list}   \n",
    "    \n",
    "for road_type in type_list:\n",
    "    df_roadtype_2[road_type].rename(columns=name2,inplace='True')\n",
    "    df_roadtype_2[road_type].drop(['1st_Road_Class_y'],axis=1,inplace='True')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting all the dicts together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols =  df_roadname_1['A1'].columns\n",
    "df_out = pd.DataFrame(columns=cols)\n",
    "    \n",
    "for road_name in road_list:\n",
    "    df_out = pd.concat([df_out,df_roadname_2[road_name]])\n",
    "    \n",
    "for road_type in type_list: \n",
    "    df_out = pd.concat([df_out,df_roadtype_2[road_type]])\n",
    "\n",
    "df_out.sort_index(inplace='True')\n",
    "df_out = df_out[['1st_Road_Class','Road_Name', 'Accident_Index', 'Assign_Type','CP_1', 'CP_2', 'CP_Index_1', 'CP_Index_2', 'Distance_1', 'Distance_2',\n",
    "        'Fd2WMV_1', 'Fd2WMV_2', 'FdAll_GV_1', 'FdAll_GV_2', 'FdAll_MV_1','FdAll_MV_2', 'FdBUS_1', 'FdBUS_2', 'FdCar_1', 'FdCar_2', 'FdPC_1',\n",
    "        'FdPC_2', 'Lat_S_1', 'Lat_S_2', 'Lon_S_1', 'Lon_S_2', ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check to see if everything's worked correctly (Should return 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(df_knn) - len(df_out) - len(df_knn[(df_knn['Assign_Type'] == 'None')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning Count Points based upon Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Formula to assign weight to each of the 3 CP counts and create an estimated traffic count for All Motor Vehicles (All_MV), Cycles (PC) and All Traffic (AT)\n",
    "\n",
    "def missing(row):\n",
    "    if pd.isnull(row['CP_2']) == True:     # isnull() function\n",
    "        return 'Missing'\n",
    "    elif pd.notnull(row['CP_2']) == True:  # notnull() function\n",
    "        return 'Not Missing'\n",
    "    \n",
    "df_out['Missing'] = df_out.apply(missing,axis=1)\n",
    "\n",
    "df_out_1 = df_out[(df_out['Missing'] == 'Not Missing')]\n",
    "df_out_2 = df_out[(df_out['Missing'] == 'Missing')]\n",
    "\n",
    "df_out_1['Total_Distance'] = df_out_1['Distance_1'] + df_out_1['Distance_2']\n",
    "df_out_1['Distance_1_Rel'] = df_out_1['Total_Distance'] - df_out_1['Distance_1']\n",
    "df_out_1['Distance_2_Rel'] = df_out_1['Total_Distance'] - df_out_1['Distance_2']\n",
    "df_out_1['Total_Rel'] = df_out_1['Distance_1_Rel'] + df_out_1['Distance_2_Rel']\n",
    "df_out_1['CP_1_%'] =  df_out_1['Distance_1_Rel'] / df_out_1['Total_Rel']\n",
    "df_out_1['CP_2_%'] =  df_out_1['Distance_2_Rel'] / df_out_1['Total_Rel']\n",
    "\n",
    "df_out_1['CP_1_MV_Val'] = df_out_1['FdAll_MV_1'] * df_out_1['CP_1_%']\n",
    "df_out_1['CP_1_PC_Val'] = df_out_1['FdPC_1']     * df_out_1['CP_1_%']\n",
    "df_out_1['CP_1_GV_Val'] = df_out_1['FdAll_GV_1'] * df_out_1['CP_1_%']\n",
    "df_out_1['CP_1_BUS_Val'] = df_out_1['FdBUS_1'] * df_out_1['CP_1_%']\n",
    "df_out_1['CP_1_CAR_Val'] = df_out_1['FdCar_1'] * df_out_1['CP_1_%']\n",
    "df_out_1['CP_1_2WMV_Val'] = df_out_1['Fd2WMV_1'] * df_out_1['CP_1_%']\n",
    "\n",
    "df_out_1['CP_2_MV_Val'] = df_out_1['FdAll_MV_2'] * df_out_1['CP_2_%']\n",
    "df_out_1['CP_2_PC_Val'] = df_out_1['FdPC_2']     * df_out_1['CP_2_%']\n",
    "df_out_1['CP_2_GV_Val'] = df_out_1['FdAll_GV_2'] * df_out_1['CP_2_%']\n",
    "df_out_1['CP_2_BUS_Val'] = df_out_1['FdBUS_2'] * df_out_1['CP_2_%']\n",
    "df_out_1['CP_2_CAR_Val'] = df_out_1['FdCar_2'] * df_out_1['CP_2_%']\n",
    "df_out_1['CP_2_2WMV_Val'] = df_out_1['Fd2WMV_2'] * df_out_1['CP_2_%']\n",
    "\n",
    "df_out_1['FdAll_MV'] = df_out_1['CP_1_MV_Val'] + df_out_1['CP_2_MV_Val'] \n",
    "df_out_1['FdPC'] = df_out_1['CP_1_PC_Val'] + df_out_1['CP_2_PC_Val']\n",
    "df_out_1['FdAll_GV'] = df_out_1['CP_1_GV_Val'] + df_out_1['CP_2_GV_Val']\n",
    "df_out_1['FdBUS'] = df_out_1['CP_1_BUS_Val'] + df_out_1['CP_2_BUS_Val']\n",
    "df_out_1['FdCar'] = df_out_1['CP_1_CAR_Val'] + df_out_1['CP_2_CAR_Val']\n",
    "df_out_1['Fd2WMV'] = df_out_1['CP_1_2WMV_Val'] + df_out_1['CP_2_2WMV_Val']\n",
    "\n",
    "df_out_2['FdAll_MV'] = df_out_2['FdAll_MV_1'] \n",
    "df_out_2['FdPC'] = df_out_2['FdPC_1']\n",
    "df_out_2['FdAll_GV'] = df_out_2['FdAll_GV_1'] \n",
    "df_out_2['FdBUS'] = df_out_2['FdBUS_1']\n",
    "df_out_2['FdCar'] = df_out_2['FdCar_1']\n",
    "df_out_2['Fd2WMV'] = df_out_2['Fd2WMV_1']\n",
    "\n",
    "df_out = pd.concat([df_out_1,df_out_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_cas_out = pd.merge(df_cas,df_out,left_on='Accident_Index',right_on='Accident_Index',how='left')\n",
    "df_cas_out.rename(columns={'Casualty_Lon':'S_Lon','Casualty_Lat':'S_Lat'},inplace='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_cas_out[(df_cas_out['Police_Force'].isin(['Metropolitan Police','City of London']))].to_csv(out + 'Casualties.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(df_cas_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
